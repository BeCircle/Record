# 《大数据搜索引擎原理分析与编程实践》笔记
Author: 王必权

Date: 20180620
## 搜索引擎基本架构

爬虫服务、索引服务、缓存服务、搜索服务、日志服务

## 自然语言处理

1. 英文分词

	波特词干算法

1. 中文分词

  基于词库的分词技术
  	a. 正向最大匹配：每次从头开始读取最大文本长度之后，去词库查询该词是否存在，如果不存在则减少一个字再去查找。
  	b. 逆向最大匹配：

  基于条件随机场的中文分词

1. 语义相似度

1. 依存句法分析

		a. 分词与词性标注
		b. 确定图节点
		c. 生成有向图
		d. 利用Prim算法构造最大生成树

1. 情感倾向分析

		a. 否定词：注意多重否定
		b. 程度副词
		c. 关系连词
		d. 句子类型

1. 文档关键词抽取

		a. 基于TF－TDF算法：每个字词的重要性随着它在文件中出现的次数成正比，与它在其他文件中出现的次数成反比
		b. 基于TextRank

1. 文档句子相似度分析

		a. 分词处理
		b. 计算词频：对于其他句子中存在，而本句中不存在的词语，设定词频值为0.
		c. 构建词频向量
		d. 向量相似度计算

1. 文档相似度

		a. Tri-Gram提取有序序列
		b. 去重过滤
		c. 共同的有序词组越多文档相似度越高

1. 文档核心句抽取
	
	类似于 TextRank，在关键词计算中以词语为单位进行计算，在文档摘要中则以句子为单位。

		a. 进行断句预处理
		b. 对每个句子进行分词及词性标注处理，并过滤掉停用词及部分词性无关词汇，再利用TextRank计算每个句子中词语的权重，并筛选出每个句子中词语权重最高的前三个关键词。
		c. 通过关键词计算句子之间的关系紧密程度，以相同的关键词数量作为紧密值
		d. 句子之间相互投票

1. 聚类分类

	文本分类：朴素贝叶斯

		a. 数据准备：根据具体情况确定特征属性，并对每个属性进行适当划分，然后由人工对一部分待分类项进行分类，形成训练样本集合。
		b. 分类器训练：计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录。
		c. 分类识别：使用分类器对待分类项进行分类。
	
	文本聚类：一种无监督的机器学习方法，不需要通过语料库训练，也不需要早期的人工标注类型。

		a. 自上而下：先把所有样本视为一个聚类，然后不断从这个大的聚类中分离出更多小聚类，直到不能继续分离为止。
		b. 自下而上：将局部样本形成一个小的聚类，然后通过不断聚合小聚类，最终形成几个大的聚类。
	
		K-Means算法：空间中有N个点，作为中心聚类点，将N个点分别与K个点计算距离，选择最近的作为自己的中心点，不断地更新中心聚集点。
	
			(1) 通过分词，过滤掉停用词
			(2) 设定K值（聚类数量），计算距离
				句子的距离约定为句子的相似度
			(3) 不断迭代计算
				迭代计算前，需要选择彼此距离较远的（k个）点作为中心聚类点
1. 语种检测

	采用N-Gram的语言模型，并结合TF-IDF进行语种检测

		a. N-Gram分词
		b. TF-IDF权值计算
		c. 语种检测

## 知识图谱

实体，实体标签，实体关系

### 实体抽取

通过自然语言处理中的分词处理和词性标注实现

### 关系抽取
1. 隐匿关系抽取

	支持向量机（SVM）: 斜面即超平面，平面内的点距离超平面的距离可以作为分类预测的准确度评判依据。若某一平面是支持向量机的最大间隔值，则这个平面也称为最大间隔超平面，此时这个支持向量机的分类器又称为最大间隔分类器。

	支持向量机线性不可分：这时将数据特征映射到高维空间。
	
	核函数：将特征进行低维转换到高维，但它依然在低维进行计算。

	实体关系抽取采用支持向量机，核心在于选择合适的特征集：实体词特征集，实体词性特征集，实体标签特征集，实体距离特征集。

	语料库准备好后进行下面的工作：
	
		a. 特征抽取及特征向量的构造。
		b. 对特征向量降维处理。利用特征选择算法对第一步的特征向量进行特征选择，重新构造新的低维特征向量。
		c. 构造SVM分类器。

1. 结构化确定关系抽取

	可直接获取的实体及关系。
1. 非结构化确定关系抽取

	基于词性序列的句子分析，简单地说就是通过词性的相关序列进行抽取，同基于统计的分词方法类似，只不过观察序列不再是字而是词性。

		a. 原始语料库预处理
		b. 人工标记实体中的关系信息
		c. 形成最终语料库。
		d. 设计算法模型(条件随机场)

### 知识图谱检测

知识图谱的检测包括实体关系修正、实体对齐及实体歧义分析。

1. 实体关系修正

	通过投票的形式去纠正实体关系。
1. 实体对齐整合
	整合原则：

		a. 具有相同属性与属性值的实体。
		b. 实体对外实体关系中，绝大部分实体关系存在子集或者包含关系。
		c. 实体字符描述语义相似度极高。
	先通过聚类的方式，让可能相似的放在一个聚簇空间，然后通过相同的属性索引进行实体比对。
1. 实体歧义分析

### 知识推理与计算

1. 知识推理

	知识推理的核心是实体之间关系的相互推导，关系推导过程中最重要的是关系识别与匹配。
1. 知识计算

	知识计算是实体与实体之间相互关系的动态结果，目前知识计算主要运用与知识信息值计算与知识关系度计算

	知识信息值计算：与数值相关
	知识关系度计算：两个实体在知识图谱中的距离越远，关系度越低。使用Dijkstra算法计算
### 知识聚类

DBSCAN：一种基于密度的聚类算法，指定范围内，拥有超过指定的点数量，则形成一个聚簇。

### 智能搜索实现

将用户的自然语言转换为系统可识别的N条查询语句。主要通过模式匹配、知识拆解、合并求解三个层次渐进分析。

## 索引机制
### 倒排索引
通过hash表或者B+树建立二级索引

构建过程：
	
	a. 提取文档
	b. 文档分词
	c. 词权重计算：对正向索引中的词进行权重计算。
	d. 索引排序：根据正向索引生成倒排索引，并对倒排索引中的内容进行排序，包括对词排序和对文档列表排序。
		词语排序：
		文档排序：根据权重排序
	e. 压缩入库：构建二级索引并对索引数据进行压缩，将压缩之后的倒排索引存入索引库。
		文档编码差值化：基于第一个元素，后面的文档编码按照与第一个文档的差值进行存储。
		词语哈希化或者哈夫曼编码：
		文档拆减：权重极低拆减、过滤拆减

更新策略：
	完全更新策略；
	合并更新策略;

### 分布式存储
划分存储方式：基于文档进行分布式存储、基于词语进行分布式划分
存储平衡策略：一致性hash算法：增加虚拟节点解决数据倾斜问题。

### 存储索引
B+树与文件索引: 只需对词编号建立B+树索引，树的节点存储词编号和索引存储地址。

除了利用B+树构建这样一个关系，还会在每次倒排索引数据插入过程中构建基于权重的B+树，即，对于一个给定的词，需要按照权重构建索引，从高到低依次排序。

字典树：字典树主要用于搜索引擎的智能提示
## 搜索服务
1. 不安全信息过滤

	Aho-Corasick算法，一种多模式匹配算法
1. 文本纠错

	N-Gram语言模型
1. 结果显示

	KMP算法匹配字符串，最终实现关键词高亮。
1. 网页排序

	基于PageRank的网页重要性评价
	基于Hits算法的网页权威性评价
	Hilltop算法

1. 图片搜索

	感知哈希算法实现以图搜图

1. 广告

	User-Based 协同过滤广告投放：以相似用户的方式进行广告投放